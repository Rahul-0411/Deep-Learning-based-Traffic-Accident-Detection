{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-30T15:56:10.406033Z",
     "iopub.status.busy": "2025-03-30T15:56:10.405855Z",
     "iopub.status.idle": "2025-03-30T15:56:15.810195Z",
     "shell.execute_reply": "2025-03-30T15:56:15.809511Z",
     "shell.execute_reply.started": "2025-03-30T15:56:10.406014Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        pass\n",
    "        # print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T15:56:18.201928Z",
     "iopub.status.busy": "2025-03-30T15:56:18.201616Z",
     "iopub.status.idle": "2025-03-30T16:07:26.069488Z",
     "shell.execute_reply": "2025-03-30T16:07:26.068699Z",
     "shell.execute_reply.started": "2025-03-30T15:56:18.201899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Multi-GPU Training with 2 GPUs\n",
      "Found 6401 images belonging to 2 classes.\n",
      "Found 1599 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 436ms/step - accuracy: 0.6837 - loss: nan - val_accuracy: 0.7675 - val_loss: 0.4829\n",
      "Epoch 2/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 292ms/step - accuracy: 0.8904 - loss: nan - val_accuracy: 0.7088 - val_loss: 0.5333\n",
      "Epoch 3/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 288ms/step - accuracy: 0.9264 - loss: nan - val_accuracy: 0.7450 - val_loss: 0.4873\n",
      "Epoch 4/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 290ms/step - accuracy: 0.9291 - loss: nan - val_accuracy: 0.5900 - val_loss: 0.8843\n",
      "Epoch 5/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 290ms/step - accuracy: 0.9316 - loss: nan - val_accuracy: 0.6050 - val_loss: 0.8908\n",
      "Epoch 6/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 289ms/step - accuracy: 0.9437 - loss: nan - val_accuracy: 0.6587 - val_loss: 0.7838\n",
      "Epoch 7/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 287ms/step - accuracy: 0.9474 - loss: nan - val_accuracy: 0.6112 - val_loss: 1.0520\n",
      "Epoch 8/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 292ms/step - accuracy: 0.9548 - loss: nan - val_accuracy: 0.5900 - val_loss: 1.3376\n",
      "Epoch 9/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 291ms/step - accuracy: 0.9533 - loss: nan - val_accuracy: 0.5788 - val_loss: 1.2149\n",
      "Epoch 10/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 292ms/step - accuracy: 0.9635 - loss: nan - val_accuracy: 0.6237 - val_loss: 1.0435\n",
      "Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)  # Prevent memory overflow\n",
    "\n",
    "        if len(gpus) > 1:\n",
    "            strategy = tf.distribute.MirroredStrategy()  # Use multiple GPUs (T4 x2 case)\n",
    "            print(f\"Using Multi-GPU Training with {len(gpus)} GPUs\")\n",
    "        else:\n",
    "            strategy = tf.distribute.OneDeviceStrategy(device=\"/GPU:0\")  # Single GPU (P100 case)\n",
    "            print(\"Using Single-GPU Training\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/CPU:0\")  # Fallback to CPU if no GPU\n",
    "    print(\"Using CPU (No GPU detected)\")\n",
    "\n",
    "# Data paths\n",
    "dataset_path = \"/kaggle/input/train1/Train1\"  # Update with your dataset path\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x) \n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "\n",
    "\n",
    "model.save(\"resnet_accident_classifier.h5\")\n",
    "print(\"Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:17:36.877548Z",
     "iopub.status.busy": "2025-03-30T16:17:36.877257Z",
     "iopub.status.idle": "2025-03-30T16:17:37.886453Z",
     "shell.execute_reply": "2025-03-30T16:17:37.885473Z",
     "shell.execute_reply.started": "2025-03-30T16:17:36.877527Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)  \n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)  \n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:17:37.887803Z",
     "iopub.status.busy": "2025-03-30T16:17:37.887507Z",
     "iopub.status.idle": "2025-03-30T16:27:23.913117Z",
     "shell.execute_reply": "2025-03-30T16:27:23.912180Z",
     "shell.execute_reply.started": "2025-03-30T16:17:37.887779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 350ms/step - accuracy: 0.7485 - loss: 0.5273 - val_accuracy: 0.5810 - val_loss: 0.8596\n",
      "Epoch 2/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 271ms/step - accuracy: 0.9077 - loss: 0.2321 - val_accuracy: 0.7217 - val_loss: 0.5589\n",
      "Epoch 3/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 272ms/step - accuracy: 0.9296 - loss: 0.1749 - val_accuracy: 0.6560 - val_loss: 0.8350\n",
      "Epoch 4/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 271ms/step - accuracy: 0.9479 - loss: 0.1390 - val_accuracy: 0.7317 - val_loss: 0.6479\n",
      "Epoch 5/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 274ms/step - accuracy: 0.9220 - loss: 0.1847 - val_accuracy: 0.5553 - val_loss: 1.5253\n",
      "Epoch 6/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 267ms/step - accuracy: 0.9490 - loss: 0.1295 - val_accuracy: 0.5985 - val_loss: 1.2708\n",
      "Epoch 7/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 269ms/step - accuracy: 0.9586 - loss: 0.0995 - val_accuracy: 0.6054 - val_loss: 1.1868\n",
      "Epoch 8/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 261ms/step - accuracy: 0.9571 - loss: 0.1101 - val_accuracy: 0.5385 - val_loss: 1.4000\n",
      "Epoch 9/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 266ms/step - accuracy: 0.9150 - loss: 0.1958 - val_accuracy: 0.7655 - val_loss: 0.5794\n",
      "Epoch 10/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 271ms/step - accuracy: 0.9526 - loss: 0.1155 - val_accuracy: 0.5553 - val_loss: 2.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e10adb433a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, validation_data=val_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:29:08.842737Z",
     "iopub.status.busy": "2025-03-30T16:29:08.842429Z",
     "iopub.status.idle": "2025-03-30T17:13:03.771060Z",
     "shell.execute_reply": "2025-03-30T17:13:03.770107Z",
     "shell.execute_reply.started": "2025-03-30T16:29:08.842715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6401 images belonging to 2 classes.\n",
      "Found 1599 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 765ms/step - accuracy: 0.9160 - loss: 0.1581 - val_accuracy: 0.4115 - val_loss: 2.0153 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 612ms/step - accuracy: 0.9940 - loss: 0.0193 - val_accuracy: 0.4115 - val_loss: 1.5609 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 618ms/step - accuracy: 0.9897 - loss: 0.0288 - val_accuracy: 0.4115 - val_loss: 4.0186 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 616ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.6904 - val_loss: 1.9063 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.9937 - loss: 0.0258\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 615ms/step - accuracy: 0.9937 - loss: 0.0258 - val_accuracy: 0.7824 - val_loss: 1.6397 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 619ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9462 - val_loss: 0.4272 - learning_rate: 5.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 616ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 0.9431 - val_loss: 0.4765 - learning_rate: 5.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 610ms/step - accuracy: 0.9992 - loss: 0.0049 - val_accuracy: 0.9475 - val_loss: 0.9542 - learning_rate: 5.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.9978 - loss: 0.0090\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 616ms/step - accuracy: 0.9978 - loss: 0.0090 - val_accuracy: 0.9481 - val_loss: 0.6095 - learning_rate: 5.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 609ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9368 - val_loss: 0.7408 - learning_rate: 2.5000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 618ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9418 - val_loss: 0.6292 - learning_rate: 2.5000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 1.0000 - loss: 8.5146e-04\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 615ms/step - accuracy: 1.0000 - loss: 8.5356e-04 - val_accuracy: 0.9275 - val_loss: 0.8111 - learning_rate: 2.5000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 613ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9256 - val_loss: 0.9281 - learning_rate: 1.2500e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 611ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.9431 - val_loss: 0.8536 - learning_rate: 1.2500e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.9999 - loss: 0.0013\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 619ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9487 - val_loss: 0.5795 - learning_rate: 1.2500e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 614ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9443 - val_loss: 0.6923 - learning_rate: 6.2500e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 612ms/step - accuracy: 0.9998 - loss: 5.9296e-04 - val_accuracy: 0.9481 - val_loss: 0.6434 - learning_rate: 6.2500e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 0.9989 - loss: 0.0012\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 606ms/step - accuracy: 0.9989 - loss: 0.0012 - val_accuracy: 0.9475 - val_loss: 0.6893 - learning_rate: 6.2500e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 615ms/step - accuracy: 1.0000 - loss: 3.3059e-04 - val_accuracy: 0.9468 - val_loss: 0.7068 - learning_rate: 3.1250e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 612ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.9468 - val_loss: 0.8189 - learning_rate: 3.1250e-06\n",
      "✅ Model Training Complete!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x) \n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"/kaggle/input/train1/Train1\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    \"/kaggle/input/train1/Train1\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "class_labels = train_generator.classes\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(class_labels), y=class_labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=AdamW(learning_rate=1e-4, weight_decay=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3, verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    class_weight=class_weight_dict,  \n",
    "    callbacks=[lr_scheduler]\n",
    ")\n",
    "\n",
    "\n",
    "model.save(\"resnet_accident_classifier_finetunedhh.h5\")\n",
    "print(\"✅ Model Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T17:27:59.878180Z",
     "iopub.status.busy": "2025-03-30T17:27:59.877544Z",
     "iopub.status.idle": "2025-03-30T17:28:00.748653Z",
     "shell.execute_reply": "2025-03-30T17:28:00.747905Z",
     "shell.execute_reply.started": "2025-03-30T17:27:59.878150Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"train1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7005114,
     "sourceId": 11217536,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
